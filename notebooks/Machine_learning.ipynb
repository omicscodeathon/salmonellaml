{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75a9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##**************************************************************************************##\n",
    "##                     Step1. Load Packages and Input Data                              ##          \n",
    "##**************************************************************************************##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm,metrics\n",
    "from sklearn.svm import SVC,LinearSVC \n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef,auc, roc_curve,plot_roc_curve, plot_precision_recall_curve,classification_report, confusion_matrix,average_precision_score, precision_recall_curve\n",
    "from pandas.core.frame import DataFrame\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "############################# input data processing #####################\n",
    "data = pd.read_csv(\"data.csv\") \n",
    "pheno = pd.read_csv(\"pheno.csv\",index_col=0)   \n",
    "data.shape,pheno.shape\n",
    "data2 = data.values\n",
    "pheno2 = pheno.values.reshape(pheno.shape[0],)\n",
    "data2.shape,pheno2.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(data2, pheno2, test_size= 0.20, stratify= pheno2, random_state= 123)\n",
    "X = X_train\n",
    "y = y_train\n",
    "X.shape,y.shape\n",
    "\n",
    "##**************************************************************************************##\n",
    "##                     Step2. Training and evaluation of RF,LR, SVM                     ##          \n",
    "##**************************************************************************************##\n",
    "\n",
    "## cross validation\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "lr = LogisticRegression(solver = 'lbfgs',max_iter=1000)\n",
    "svm = SVC(kernel='linear', probability=True)\n",
    "\n",
    "##*************** F1 + ROC curve\n",
    "## RF\n",
    "rf_tprs = []\n",
    "rf_prs = []\n",
    "rf_roc_aucs = []\n",
    "rf_pr_aucs = []\n",
    "rf_f1_matrix_out = []\n",
    "rf_f1_report_out = []\n",
    "rf_MCC_out = []\n",
    "rf_pred_cls_out = []\n",
    "rf_pred_prob_out = []\n",
    "rf_y_test_out = []\n",
    "rf_mean_fpr = np.linspace(0, 1, 100)\n",
    "rf_mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "## LR\n",
    "lr_tprs = []\n",
    "lr_prs = []\n",
    "lr_roc_aucs = []\n",
    "lr_pr_aucs = []\n",
    "lr_f1_matrix_out = []\n",
    "lr_f1_report_out = []\n",
    "lr_MCC_out = []\n",
    "lr_pred_cls_out = []\n",
    "lr_pred_prob_out = []\n",
    "lr_y_test_out = []\n",
    "lr_mean_fpr = np.linspace(0, 1, 100)\n",
    "lr_mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "## SVM\n",
    "svm_tprs = []\n",
    "svm_prs = []\n",
    "svm_roc_aucs = []\n",
    "svm_pr_aucs = []\n",
    "svm_f1_matrix_out = []\n",
    "svm_f1_report_out = []\n",
    "svm_MCC_out = []\n",
    "svm_pred_cls_out = []\n",
    "svm_pred_prob_out = []\n",
    "svm_y_test_out = []\n",
    "svm_mean_fpr = np.linspace(0, 1, 100)\n",
    "svm_mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "fig,[ax1,ax2,ax3] = plt.subplots(nrows=1,ncols=3,figsize=(15, 4))\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "    ## train the new model\n",
    "    rf.fit(X[train], y[train])\n",
    "    ## roc curve\n",
    "    rf_viz = plot_roc_curve(rf, X[test], y[test],name='K fold {}'.format(i),alpha=0.3, lw=1,ax=ax1)\n",
    "    rf_interp_tpr = np.interp(rf_mean_fpr, rf_viz.fpr, rf_viz.tpr)\n",
    "    rf_interp_tpr[0] = 0.0\n",
    "    rf_tprs.append(rf_interp_tpr)\n",
    "    rf_roc_aucs.append(rf_viz.roc_auc) \n",
    "    ## evaluation metrics \t\n",
    "    rf_pred_cls = rf.predict(X[test])\n",
    "    rf_pred_prob = rf.predict_proba(X[test])[:,1]\n",
    "    rf_f1_matrix = confusion_matrix(y[test],rf_pred_cls)\n",
    "    rf_f1_report = classification_report(y[test],rf_pred_cls)\n",
    "    rf_MCC = matthews_corrcoef(y[test],rf_pred_cls)\n",
    "    ### save evalu_metrics out\n",
    "    rf_pred_cls_out.append(rf_pred_cls)\n",
    "    rf_pred_prob_out.append(rf_pred_prob)\n",
    "    rf_f1_matrix_out.append(rf_f1_matrix)\n",
    "    rf_f1_report_out.append(rf_f1_report)\n",
    "    rf_MCC_out.append(rf_MCC)\n",
    "    rf_y_test_out.append(y[test])\n",
    "    \n",
    "    ## LR\n",
    "    lr.fit(X[train], y[train])\n",
    "    ## roc curve\n",
    "    lr_viz = plot_roc_curve(lr, X[test], y[test],name='K fold {}'.format(i),alpha=0.3, lw=1,ax=ax2)\n",
    "    lr_interp_tpr = np.interp(lr_mean_fpr, lr_viz.fpr, lr_viz.tpr)\n",
    "    lr_interp_tpr[0] = 0.0\n",
    "    lr_tprs.append(lr_interp_tpr)\n",
    "    lr_roc_aucs.append(lr_viz.roc_auc) \n",
    "    ## evaluation metrics \t\n",
    "    lr_pred_cls = lr.predict(X[test])\n",
    "    lr_pred_prob = lr.predict_proba(X[test])[:,1]\n",
    "    lr_f1_matrix = confusion_matrix(y[test],lr_pred_cls)\n",
    "    lr_f1_report = classification_report(y[test],lr_pred_cls)\n",
    "    lr_MCC = matthews_corrcoef(y[test],lr_pred_cls)\n",
    "    ### save evalu_metrics out\n",
    "    lr_pred_cls_out.append(lr_pred_cls)\n",
    "    lr_pred_prob_out.append(lr_pred_prob)\n",
    "    lr_f1_matrix_out.append(lr_f1_matrix)\n",
    "    lr_f1_report_out.append(lr_f1_report)\n",
    "    lr_MCC_out.append(lr_MCC)\n",
    "    lr_y_test_out.append(y[test])\n",
    "    \n",
    "    ## SVM\n",
    "    svm.fit(X[train], y[train])\n",
    "    ## roc curve\n",
    "    svm_viz = plot_roc_curve(svm, X[test], y[test],name='K fold {}'.format(i),alpha=0.3, lw=1,ax=ax3)\n",
    "    svm_interp_tpr = np.interp(svm_mean_fpr, svm_viz.fpr, svm_viz.tpr)\n",
    "    svm_interp_tpr[0] = 0.0\n",
    "    svm_tprs.append(svm_interp_tpr)\n",
    "    svm_roc_aucs.append(svm_viz.roc_auc) \n",
    "    ## evaluation metrics \t\n",
    "    svm_pred_cls = svm.predict(X[test])\n",
    "    svm_pred_prob = svm.predict_proba(X[test])[:,1]\n",
    "    svm_f1_matrix = confusion_matrix(y[test],svm_pred_cls)\n",
    "    svm_f1_report = classification_report(y[test],svm_pred_cls)\n",
    "    svm_MCC = matthews_corrcoef(y[test],svm_pred_cls)\n",
    "    ### save evalu_metrics out\n",
    "    svm_pred_cls_out.append(svm_pred_cls)\n",
    "    svm_pred_prob_out.append(svm_pred_prob)\n",
    "    svm_f1_matrix_out.append(svm_f1_matrix)\n",
    "    svm_f1_report_out.append(svm_f1_report)\n",
    "    svm_MCC_out.append(svm_MCC)\n",
    "    svm_y_test_out.append(y[test])\n",
    "    \n",
    "\n",
    "### save mcc and f1-report\n",
    "rf_mcc = pd.DataFrame(rf_MCC_out) \n",
    "lr_mcc = pd.DataFrame(lr_MCC_out) \n",
    "svm_mcc = pd.DataFrame(svm_MCC_out) \n",
    "all_mcc = pd.concat([rf_mcc,lr_mcc,svm_mcc],axis=1)\n",
    "all_mcc.columns = ['RF_MCC','LR_MCC','SVM_MCC']\n",
    "all_mcc.to_csv(\"Train_MCC.csv\",index=False)   \n",
    "\n",
    "rf_f1_report = pd.DataFrame(rf_f1_report_out)\n",
    "rf_f1_report.columns=['RF'] \n",
    "lr_f1_report = pd.DataFrame(lr_f1_report_out) \n",
    "lr_f1_report.columns=['LR']\n",
    "svm_f1_report = pd.DataFrame(svm_f1_report_out) \n",
    "svm_f1_report.columns=['SVM']\n",
    "all_f1_report = pd.concat([rf_f1_report,lr_f1_report,svm_f1_report],axis=0)   \n",
    "all_f1_report.to_csv(\"Train_F1_report.csv\",index=False)   \n",
    "\n",
    "\n",
    "###************************** plot training results and save mean tpr and fpr **********************************\n",
    "######### RF\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', alpha=.8)\n",
    "rf_mean_tpr = np.mean(rf_tprs, axis=0)\n",
    "rf_mean_tpr[-1] = 1.0\n",
    "rf_mean_auc = auc(rf_mean_fpr, rf_mean_tpr)\n",
    "rf_std_auc = np.std(rf_roc_aucs)\n",
    "ax1.plot(rf_mean_fpr, rf_mean_tpr, color='b',label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.2f)' % (rf_mean_auc, rf_std_auc),lw=2, alpha=.8)\n",
    "rf_std_tpr = np.std(rf_tprs, axis=0)\n",
    "rf_tprs_upper = np.minimum(rf_mean_tpr + rf_std_tpr, 1)\n",
    "rf_tprs_lower = np.maximum(rf_mean_tpr - rf_std_tpr, 0)\n",
    "ax1.fill_between(rf_mean_fpr, rf_tprs_lower, rf_tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "ax1.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title=\"RF ROC Curve\")\n",
    "ax1.legend(loc=\"lower right\",prop = {'size':6})\n",
    "\n",
    "#plt.savefig(\"Train_RF_ROC.pdf\")  \n",
    "### save mean FPR and TPR\n",
    "#np.savetxt(\"Train_RF_mean_fpr.csv\",rf_mean_fpr,delimiter=\",\")\n",
    "#np.savetxt(\"Train_RF_mean_tpr.csv\",rf_mean_tpr,delimiter=\",\")\n",
    "\n",
    "######### LR\n",
    "ax2.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', alpha=.8)\n",
    "lr_mean_tpr = np.mean(lr_tprs, axis=0)\n",
    "lr_mean_tpr[-1] = 1.0\n",
    "lr_mean_auc = auc(lr_mean_fpr, lr_mean_tpr)\n",
    "lr_std_auc = np.std(lr_roc_aucs)\n",
    "ax2.plot(lr_mean_fpr, lr_mean_tpr, color='b',label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.2f)' % (lr_mean_auc, lr_std_auc),lw=2, alpha=.8)\n",
    "lr_std_tpr = np.std(lr_tprs, axis=0)\n",
    "lr_tprs_upper = np.minimum(lr_mean_tpr + lr_std_tpr, 1)\n",
    "lr_tprs_lower = np.maximum(lr_mean_tpr - lr_std_tpr, 0)\n",
    "ax2.fill_between(lr_mean_fpr, lr_tprs_lower, lr_tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "ax2.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title=\"LR ROC Curve\")\n",
    "ax2.legend(loc=\"lower right\",prop = {'size':6})\n",
    "#plt.savefig(\"Train_LR_ROC.pdf\")  \n",
    "### save mean FPR and TPR\n",
    "#np.savetxt(\"Train_LR_mean_fpr.csv\",lr_mean_fpr,delimiter=\",\")\n",
    "#np.savetxt(\"Train_LR_mean_tpr.csv\",lr_mean_tpr,delimiter=\",\")\n",
    "\n",
    "######### SVM\n",
    "ax3.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', alpha=.8)\n",
    "svm_mean_tpr = np.mean(svm_tprs, axis=0)\n",
    "svm_mean_tpr[-1] = 1.0\n",
    "svm_mean_auc = auc(svm_mean_fpr, svm_mean_tpr)\n",
    "svm_std_auc = np.std(svm_roc_aucs)\n",
    "ax3.plot(svm_mean_fpr, svm_mean_tpr, color='b',label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.2f)' % (svm_mean_auc, svm_std_auc),lw=2, alpha=.8)\n",
    "svm_std_tpr = np.std(svm_tprs, axis=0)\n",
    "svm_tprs_upper = np.minimum(svm_mean_tpr + svm_std_tpr, 1)\n",
    "svm_tprs_lower = np.maximum(svm_mean_tpr - svm_std_tpr, 0)\n",
    "ax3.fill_between(svm_mean_fpr, svm_tprs_lower, svm_tprs_upper, color='grey', alpha=.2,label=r'$\\pm$ 1 std. dev.')\n",
    "ax3.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],title=\"SVM ROC Curve\")\n",
    "ax3.legend(loc=\"lower right\",prop = {'size':6})\n",
    "plt.savefig(\"Train_RF_LR_SVM_ROC.pdf\")  \n",
    "### save mean FPR and TPR\n",
    "#np.savetxt(\"Train_SVM_mean_fpr.csv\",svm_mean_fpr,delimiter=\",\")\n",
    "#np.savetxt(\"Train_SVM_mean_tpr.csv\",svm_mean_tpr,delimiter=\",\")\n",
    "\n",
    "\n",
    "####******************** Evaluation on test data ************************************************\n",
    "# pre_class\n",
    "rf_eva_pred = rf.predict(X_test)\n",
    "lr_eva_pred = lr.predict(X_test)\n",
    "svm_eva_pred = svm.predict(X_test)\n",
    "# pre_prob\n",
    "rf_eva_pred_prob = rf.predict_proba(X_test)[:,1]\n",
    "lr_eva_pred_prob = lr.predict_proba(X_test)[:,1]\n",
    "svm_eva_pred_prob = svm.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "## save f1 report,confusion_matrix, MCC\n",
    "f=open(\"Test_RF_LR_SVM_eva_metrics.csv\",\"w\")\n",
    "# f1 report\n",
    "print(classification_report(y_test,rf_eva_pred),file=f)\n",
    "print(classification_report(y_test,lr_eva_pred),file=f)\n",
    "print(classification_report(y_test,svm_eva_pred),file=f)\n",
    "# confusion_matrix\n",
    "print(confusion_matrix(y_test,rf_eva_pred),file=f)\n",
    "print(confusion_matrix(y_test,lr_eva_pred),file=f)\n",
    "print(confusion_matrix(y_test,svm_eva_pred),file=f)\n",
    "# MCC\n",
    "print(matthews_corrcoef(y_test,rf_eva_pred),file=f)\n",
    "print(matthews_corrcoef(y_test,lr_eva_pred),file=f)\n",
    "print(matthews_corrcoef(y_test,svm_eva_pred),file=f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "## Plot ROC curve and PR curve\n",
    "## ROC\n",
    "fig,[ax4,ax5,ax6] = plt.subplots(nrows=1,ncols=3,figsize=(15, 4))\n",
    "ax4.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', alpha=.8)\n",
    "rf_fpr, rf_tpr,thresholds = roc_curve(y_test,rf_eva_pred_prob)\n",
    "rf_roc_auc = metrics.auc(rf_fpr,rf_tpr)\n",
    "ax4.plot(rf_fpr,rf_tpr,label= 'ROC (AUC = {:.3f} )'.format(rf_roc_auc))\n",
    "ax4.set(xlabel='False Postive Rate',ylabel='True Positive Rate',title=\"RF ROC Curve\")\n",
    "ax4.legend(loc='lower right')\n",
    "\n",
    "ax5.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', alpha=.8)\n",
    "lr_fpr, lr_tpr,thresholds = roc_curve(y_test,lr_eva_pred_prob)\n",
    "lr_roc_auc = metrics.auc(lr_fpr,lr_tpr)\n",
    "ax5.plot(lr_fpr,lr_tpr,label= 'ROC (AUC = {:.3f} )'.format(lr_roc_auc))\n",
    "ax5.set(xlabel='False Postive Rate',ylabel='True Positive Rate',title=\"LR ROC Curve\")\n",
    "ax5.legend(loc='lower right')\n",
    "\n",
    "ax6.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', alpha=.8)\n",
    "svm_fpr, svm_tpr,thresholds = roc_curve(y_test,svm_eva_pred_prob)\n",
    "svm_roc_auc = metrics.auc(svm_fpr,svm_tpr)\n",
    "ax6.plot(svm_fpr,svm_tpr,label= 'ROC (AUC = {:.3f} )'.format(svm_roc_auc))\n",
    "ax6.set(xlabel='False Postive Rate',ylabel='True Positive Rate',title=\"SVM ROC Curve\")\n",
    "ax6.legend(loc='lower right')\n",
    "plt.savefig(\"Test_RF_LR_SVM_ROC_curve.pdf\",bbox_inches='tight')\n",
    "\n",
    "\n",
    "###### PR curve\n",
    "fig,[ax7,ax8,ax9] = plt.subplots(nrows=1,ncols=3,figsize=(15, 4))\n",
    "rf_precision,rf_recall,thresholds = precision_recall_curve(y_test,rf_eva_pred_prob)\n",
    "rf_pr_auc = metrics.auc(rf_recall,rf_precision)\n",
    "ax7.plot([0,1],[1,0],linestyle=\"--\",lw=2,color='k',alpha=.8)\n",
    "ax7.plot(rf_recall,rf_precision,label= '(AUCPR = {:.3f})'.format(rf_pr_auc))\n",
    "ax7.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],xlabel='Recall',ylabel='Precision',title=\"RF Precision-Recall Curve\")\n",
    "ax7.legend(loc='lower left')\n",
    "\n",
    "lr_precision,lr_recall,thresholds = precision_recall_curve(y_test,lr_eva_pred_prob)\n",
    "lr_pr_auc = metrics.auc(lr_recall,lr_precision)\n",
    "ax8.plot([0,1],[1,0],linestyle=\"--\",lw=2,color='k',alpha=.8)\n",
    "ax8.plot(lr_recall,lr_precision,label= '(AUCPR = {:.3f})'.format(lr_pr_auc))\n",
    "ax8.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],xlabel='Recall',ylabel='Precision',title=\"LR Precision-Recall Curve\")\n",
    "ax8.legend(loc='lower left')\n",
    "\n",
    "svm_precision,svm_recall,thresholds = precision_recall_curve(y_test,svm_eva_pred_prob)\n",
    "svm_pr_auc = metrics.auc(svm_recall,svm_precision)\n",
    "ax9.plot([0,1],[1,0],linestyle=\"--\",lw=2,color='k',alpha=.8)\n",
    "ax9.plot(svm_recall,svm_precision,label= '(AUCPR = {:.3f})'.format(svm_pr_auc))\n",
    "ax9.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],xlabel='Recall',ylabel='Precision',title=\"SVM Precision-Recall Curve\")\n",
    "ax9.legend(loc='lower left')\n",
    "plt.savefig(\"Test_RF_LR_SVM_PR_curve.pdf\",bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
